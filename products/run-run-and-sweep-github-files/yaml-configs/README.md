# YAML configs

## Running Sweeps using YML

You can run a hyper parameter sweep using the Grid YML file by passing the hyper\_params key. There are two sub-keys you can configure:

* **`settings`**: use to choose between different 
* **`params`**: use to configure which command-line flags are passed to your script and which values are passed

You can pass any of the supported Python or NumPy expressions to each `params` key. For example, you can pass the following:

```yaml
hyper_params:

  settings:
    strategy: random_search     # either random_search or grid_search
    trials: 2                   # only used in random_search

  params:
    learning_rate: uniform(0.001, 0.008, 20)
    gamma: 0.234
```

That will generate 20 values for the `learning_rate`.

## Using Environment Variables

You can pass in environment variables to be used by your experiment by using the **`environment`** key. Pass any values and those values will be available in your experiment context. For example:

```yaml
compute:
  train:
    environment:
      MY_ENVIRONMENT_VARIABLE: "example"
```

The environment variable **`MY_ENVIRONMENT_VARIABLE`** will be injected into your experiment runtime.

## Specifying Requirement Files

Grid will automatically install dependencies into your project using either `pip` or `conda`. It does that automatically by finding files either named `requirements.txt` or `environment.yml` in your project's root. 

If your dependencies live elsewhere, you can specify their location using the `dependency_file_info` attribute in the Grid YAML config.

```yaml
compute:
  train:
    dependency_file_info:
      package_manager: pip
      path: ./requirements/requirements.txt # can have any name 
```

## Full Example

In this example, we run a hyper parameter sweep that creates 2 experiments. That's the case because we are using `random_search` with the `trials` parameter set to 2, which will randomly sample 2 combinations of hyper parameters from the combinations generated by `learning_rate` and `gamma`.

```yaml
# Main compute configuration.
compute:

  # Add cloud configuration here.
  provider:

    credentials: XXXXXX           # Cloud key ID
    region: us-east-1             # Cloud region
    vendor: aws                   # Vendor, only aws

  # Training configuration.
  train:

    cpus: 1                       # Number of CPUs
    gpus: 0                       # Number of GPUs
    instance: t2.xlarge           # AWS instance type
    memory: null                  # RAM memory
    nodes: 0                      # Nodes to start with
    scale_down_seconds: 1800      # Second in between every scaling down evaluation

    # Your environment variables
    environment:
      MY_ENVIRONMENT_VARIABLE: "example"
      
    # Dependency file specification
    dependency_file_info:
      package_manager: pip
      path: ./requirements/requirements.txt # can have any name 

hyper_params:
  settings:
    strategy: random_search
    trials: 2
  params:
    learning_rate: uniform(0.001, 0.008, 20)
    gamma: 0.234
```


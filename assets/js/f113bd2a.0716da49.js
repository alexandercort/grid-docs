"use strict";(self.webpackChunkgrid_docs=self.webpackChunkgrid_docs||[]).push([[728],{3905:function(e,t,n){n.d(t,{Zo:function(){return p},kt:function(){return m}});var a=n(7294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var c=a.createContext({}),s=function(e){var t=a.useContext(c),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},p=function(e){var t=s(e.components);return a.createElement(c.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},u=a.forwardRef((function(e,t){var n=e.components,o=e.mdxType,r=e.originalType,c=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),u=s(n),m=o,h=u["".concat(c,".").concat(m)]||u[m]||d[m]||r;return n?a.createElement(h,i(i({ref:t},p),{},{components:n})):a.createElement(h,i({ref:t},p))}));function m(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var r=n.length,i=new Array(r);i[0]=u;var l={};for(var c in t)hasOwnProperty.call(t,c)&&(l[c]=t[c]);l.originalType=e,l.mdxType="string"==typeof e?e:o,i[1]=l;for(var s=2;s<r;s++)i[s]=n[s];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}u.displayName="MDXCreateElement"},7776:function(e,t,n){n.r(t),n.d(t,{frontMatter:function(){return l},contentTitle:function(){return c},metadata:function(){return s},toc:function(){return p},default:function(){return u}});var a=n(7462),o=n(3366),r=(n(7294),n(3905)),i=["components"],l={description:"This tutorial shows how to train Object Detection Models on Grid using Lightning Flash and the COCO format."},c="Coco Object Detection",s={unversionedId:"examples/vision/coco",id:"examples/vision/coco",title:"Coco Object Detection",description:"This tutorial shows how to train Object Detection Models on Grid using Lightning Flash and the COCO format.",source:"@site/docs/examples/vision/coco.md",sourceDirName:"examples/vision",slug:"/examples/vision/coco",permalink:"/examples/vision/coco",editUrl:"https://github.com/gridai/grid-docs/edit/master/docs/examples/vision/coco.md",tags:[],version:"current",lastUpdatedAt:1645053708,formattedLastUpdatedAt:"2/16/2022",frontMatter:{description:"This tutorial shows how to train Object Detection Models on Grid using Lightning Flash and the COCO format."}},p=[{value:"Goal",id:"goal",children:[],level:2},{value:"Tutorial time",id:"tutorial-time",children:[],level:2},{value:"Task: Object Detection",id:"task-object-detection",children:[],level:2},{value:"Dataset: COCO",id:"dataset-coco",children:[],level:2},{value:"Step 1: Model",id:"step-1-model",children:[],level:2},{value:"Step 2: Start a RUN",id:"step-2-start-a-run",children:[],level:2},{value:"Step 3: Use the model for predictions",id:"step-3-use-the-model-for-predictions",children:[],level:2},{value:"Bonus: CLI equivalent",id:"bonus-cli-equivalent",children:[],level:2}],d={toc:p};function u(e){var t=e.components,l=(0,o.Z)(e,i);return(0,r.kt)("wrapper",(0,a.Z)({},d,l,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"coco-object-detection"},"Coco Object Detection"),(0,r.kt)("h2",{id:"goal"},"Goal"),(0,r.kt)("p",null,"This example covers an object detection deep learning task"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"What is Object Detection"),(0,r.kt)("li",{parentName:"ol"},"Training the model using ",(0,r.kt)("inlineCode",{parentName:"li"},"train.py")," script"),(0,r.kt)("li",{parentName:"ol"},"Loading Grid Weights in Flash and Running Object Detector")),(0,r.kt)("div",{className:"admonition admonition-note alert alert--secondary"},(0,r.kt)("div",{parentName:"div",className:"admonition-heading"},(0,r.kt)("h5",{parentName:"div"},(0,r.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,r.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,r.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"}))),"note")),(0,r.kt)("div",{parentName:"div",className:"admonition-content"},(0,r.kt)("p",{parentName:"div"},"This tutorial uses ",(0,r.kt)("strong",{parentName:"p"},"PyTorch Lightning")))),(0,r.kt)("h2",{id:"tutorial-time"},"Tutorial time"),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"5 minutes")),(0,r.kt)("h2",{id:"task-object-detection"},"Task: Object Detection"),(0,r.kt)("p",null,(0,r.kt)("em",{parentName:"p"},"Object detection")," is the task of ",(0,r.kt)("em",{parentName:"p"},"detecting")," instances of ",(0,r.kt)("em",{parentName:"p"},"objects")," of a certain class within an image."),(0,r.kt)("h2",{id:"dataset-coco"},"Dataset: COCO"),(0,r.kt)("p",null,"The COCO ","(","Common Objects in Context",")"," ",(0,r.kt)("em",{parentName:"p"},"dataset")," ","(",(0,r.kt)("a",{parentName:"p",href:"https://cocodataset.org/"},"reference"),")"," is a large-scale object detection dataset with 91 instance classes."),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Example CoCo Images",src:n(5943).Z})),(0,r.kt)("h2",{id:"step-1-model"},"Step 1: Model"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://lightning-flash.readthedocs.io/en/latest/reference/object_detection.html"},"PyTorch Lightning Flash")," enables the quick training, fine tuning, and inferencing of SOTA object detection algorithms such as RetinaNet."),(0,r.kt)("p",null,"For this demo, we're going to be using this ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/aribornstein/CocoDemo/blob/main/train.py"},"code here")),(0,r.kt)("p",null,"Here's a preview of this code."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'import flash\nfrom flash.core.data import download_data\nfrom flash.vision import ObjectDetectionData, ObjectDetector\n\n# 1. Download the data\n# Dataset Credit: https://www.kaggle.com/ultralytics/coco128\ndownload_data("https://github.com/zhiqwang/yolov5-rt-stack/releases/download/v0.3.0/coco128.zip",\n              "data/")\n# 2. Load the Data\ndatamodule = ObjectDetectionData.from_coco(\n    train_folder=os.path.join(args.data_dir, "data/coco128/images/train2017/"),\n    train_ann_file=os.path.join(args.data_dir, "data/coco128/annotations/instances_train2017.json"),\n    batch_size=2\n)\n# 3. Build the model\nmodel = ObjectDetector(num_classes=datamodule.num_classes)\n\n# 4. Create the trainer\ntrainer = flash.Trainer(max_epochs=args.max_epochs, gpus=args.gpus)\n\n# 5. Finetune the model\ntrainer.finetune(model, datamodule)\n\n# 6. Save it!\ntrainer.save_checkpoint("object_detection_model.pt")\n')),(0,r.kt)("h2",{id:"step-2-start-a-run"},"Step 2: Start a RUN"),(0,r.kt)("p",null,"Training this model on Grid has 4 simple steps:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Create a ",(0,r.kt)("strong",{parentName:"li"},"Run"),"."),(0,r.kt)("li",{parentName:"ul"},"Copy and paste the model script.")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-text"},"https://github.com/aribornstein/CocoDemo/blob/main/train.py\n")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Select  1xT4 ","(","16 GB",")"," $0.68/h ","(","g4dn.xlarge",")"," as the Accelerator"),(0,r.kt)("li",{parentName:"ul"},"Provide the  run arguments ",(0,r.kt)("inlineCode",{parentName:"li"},"--max_epochs 5")," ",(0,r.kt)("inlineCode",{parentName:"li"},"--gpus 1"))),(0,r.kt)("p",null,(0,r.kt)("img",{parentName:"p",src:"https://www.loom.com/share/18765b8b4d794c88b93ccbcce6493884",alt:"type:video"})),(0,r.kt)("p",null,"You can add optional flags to this script:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-text"},"--train_folder /path/to/dataset\n--train_ann_file /path/to/annotations.json\n--download False\n")),(0,r.kt)("h2",{id:"step-3-use-the-model-for-predictions"},"Step 3: Use the model for predictions"),(0,r.kt)("p",null,"In this step, we load the Grid weights in Flash and run the model to detect objects."),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Download Artifacts from Grid Run")),(0,r.kt)("p",null,(0,r.kt)("img",{src:n(4820).Z})),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Load model to our script and inference in 4 lines of code.")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from flash.vision import ObjectDetector\n\n# 1. Load the model\ndetector = ObjectDetector.load_from_checkpoint("object_detection_model.pt")\n\n# 2. Perform inference on an image file\npredictions = detector.predict("path/to/image.png")\nprint(predictions)\n')),(0,r.kt)("p",null,"Congratulations you have successfully trained and run inference for your first Object Detection Model with Grid."),(0,r.kt)("h2",{id:"bonus-cli-equivalent"},"Bonus: CLI equivalent"),(0,r.kt)("p",null,"Here are the equivalent commands for the CLI"),(0,r.kt)("p",null,"First, clone the project"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"git clone https://github.com/aribornstein/CocoDemo.git\ncd CocoDemo\n")),(0,r.kt)("p",null,"Start run"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"grid run \\\n--instance_type 1_v100_16gb \\\n--framework lightning \\\n--gpus 1 \\\ntrain.py \\\n--max_epochs 5 \\\n--gpus 1\n")))}u.isMDXComponent=!0},4820:function(e,t,n){t.Z=n.p+"assets/images/coco-artifacts-33d6807074598961fc72a48f06310df0.png"},5943:function(e,t,n){t.Z=n.p+"assets/images/coco-images-b3089d58205746e3ca952efeae57a5c2.png"}}]);